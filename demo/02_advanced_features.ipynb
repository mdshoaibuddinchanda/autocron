{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e70c47",
   "metadata": {},
   "source": [
    "# AutoCron Demo 2: Advanced Features\n",
    "\n",
    "This notebook demonstrates advanced scheduling features.\n",
    "\n",
    "## Features Covered:\n",
    "- Retries and error handling\n",
    "- Timeouts\n",
    "- Task priorities\n",
    "- Task dependencies\n",
    "- Task metadata and tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b69751",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocron import AutoCron, schedule\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140fbee",
   "metadata": {},
   "source": [
    "## 1. Retries and Error Handling\n",
    "\n",
    "Tasks can automatically retry on failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe975b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task that might fail\n",
    "attempt_count = 0\n",
    "\n",
    "@schedule(every='10s', retries=3, retry_delay=5)\n",
    "def unreliable_api_call():\n",
    "    \"\"\"Simulates an unreliable API that might fail.\"\"\"\n",
    "    global attempt_count\n",
    "    attempt_count += 1\n",
    "    \n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Attempt #{attempt_count}\")\n",
    "    \n",
    "    # Simulate random failures\n",
    "    if random.random() < 0.6:  # 60% failure rate\n",
    "        print(\"  ‚ùå API call failed!\")\n",
    "        raise Exception(\"Connection timeout\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ API call succeeded!\")\n",
    "        return \"Data retrieved\"\n",
    "\n",
    "print(\"‚úÖ Task with retries scheduled!\")\n",
    "print(\"üìù Will retry up to 3 times with 5 second delay between attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scheduler class for more control\n",
    "scheduler = AutoCron()\n",
    "\n",
    "def flaky_task():\n",
    "    if random.random() < 0.5:\n",
    "        raise Exception(\"Random failure\")\n",
    "    return \"Success\"\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"flaky_task\",\n",
    "    func=flaky_task,\n",
    "    every='15s',\n",
    "    retries=5,           # Retry up to 5 times\n",
    "    retry_delay=3        # Wait 3 seconds between retries\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Task added with 5 retries and 3 second delay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b3444",
   "metadata": {},
   "source": [
    "## 2. Timeouts\n",
    "\n",
    "Prevent tasks from running too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe11ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@schedule(every='20s', timeout=10)\n",
    "def long_running_task():\n",
    "    \"\"\"Task that might take too long.\"\"\"\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting long task...\")\n",
    "    \n",
    "    # Simulate long processing\n",
    "    duration = random.randint(5, 15)\n",
    "    print(f\"  Processing for {duration} seconds...\")\n",
    "    time.sleep(duration)\n",
    "    \n",
    "    print(\"  ‚úÖ Task completed!\")\n",
    "    return \"Done\"\n",
    "\n",
    "print(\"‚úÖ Task with 10-second timeout scheduled!\")\n",
    "print(\"‚è±Ô∏è  If task takes longer than 10 seconds, it will be terminated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining timeout with retries\n",
    "scheduler = AutoCron()\n",
    "\n",
    "def slow_processing():\n",
    "    time.sleep(random.randint(3, 8))\n",
    "    return \"Processed\"\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"slow_processor\",\n",
    "    func=slow_processing,\n",
    "    every='30s',\n",
    "    timeout=5,           # 5 second timeout\n",
    "    retries=2,           # Retry if timeout\n",
    "    retry_delay=2\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Task with timeout + retries configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0587c",
   "metadata": {},
   "source": [
    "## 3. Task Priorities\n",
    "\n",
    "Control execution order when multiple tasks are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c425463",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AutoCron()\n",
    "\n",
    "def critical_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] üî¥ CRITICAL: Security check\")\n",
    "\n",
    "def high_priority_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] üü† HIGH: Data backup\")\n",
    "\n",
    "def normal_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] üü¢ NORMAL: Log rotation\")\n",
    "\n",
    "def low_priority_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] üîµ LOW: Cache cleanup\")\n",
    "\n",
    "# Add tasks with different priorities (higher number = higher priority)\n",
    "scheduler.add_task(name=\"critical\", func=critical_task, every='10s', priority=10)\n",
    "scheduler.add_task(name=\"high\", func=high_priority_task, every='10s', priority=7)\n",
    "scheduler.add_task(name=\"normal\", func=normal_task, every='10s', priority=5)\n",
    "scheduler.add_task(name=\"low\", func=low_priority_task, every='10s', priority=2)\n",
    "\n",
    "print(\"‚úÖ Tasks with different priorities scheduled!\")\n",
    "print(\"üìä Priority levels: 10 (critical) > 7 (high) > 5 (normal) > 2 (low)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d9d09",
   "metadata": {},
   "source": [
    "## 4. Task Dependencies\n",
    "\n",
    "Run tasks only after other tasks complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AutoCron()\n",
    "\n",
    "def fetch_data():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] 1Ô∏è‚É£ Fetching raw data...\")\n",
    "    time.sleep(2)\n",
    "    return \"raw_data.csv\"\n",
    "\n",
    "def process_data():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] 2Ô∏è‚É£ Processing data...\")\n",
    "    time.sleep(2)\n",
    "    return \"processed_data.csv\"\n",
    "\n",
    "def generate_report():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] 3Ô∏è‚É£ Generating report...\")\n",
    "    time.sleep(1)\n",
    "    return \"report.pdf\"\n",
    "\n",
    "# Add tasks with dependencies\n",
    "scheduler.add_task(\n",
    "    name=\"fetch\",\n",
    "    func=fetch_data,\n",
    "    every='1h'\n",
    ")\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"process\",\n",
    "    func=process_data,\n",
    "    every='1h',\n",
    "    dependencies=[\"fetch\"]  # Runs only after 'fetch' completes\n",
    ")\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"report\",\n",
    "    func=generate_report,\n",
    "    every='1h',\n",
    "    dependencies=[\"process\"]  # Runs only after 'process' completes\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Task pipeline with dependencies configured!\")\n",
    "print(\"üìä Pipeline: fetch ‚Üí process ‚Üí report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac5d15",
   "metadata": {},
   "source": [
    "## 5. Task Metadata and Tags\n",
    "\n",
    "Organize and categorize tasks with metadata and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87233e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AutoCron()\n",
    "\n",
    "# Add tasks with metadata and tags\n",
    "scheduler.add_task(\n",
    "    name=\"db_backup\",\n",
    "    func=lambda: print(\"Backing up database...\"),\n",
    "    every='6h',\n",
    "    tags=[\"backup\", \"database\", \"critical\"],\n",
    "    metadata={\n",
    "        \"owner\": \"DevOps Team\",\n",
    "        \"database\": \"production\",\n",
    "        \"retention_days\": 30,\n",
    "        \"notification_email\": \"ops@company.com\"\n",
    "    }\n",
    ")\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"log_cleanup\",\n",
    "    func=lambda: print(\"Cleaning old logs...\"),\n",
    "    every='1d',\n",
    "    tags=[\"maintenance\", \"cleanup\"],\n",
    "    metadata={\n",
    "        \"owner\": \"Platform Team\",\n",
    "        \"cleanup_age_days\": 7,\n",
    "        \"disk_threshold_gb\": 100\n",
    "    }\n",
    ")\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"api_monitor\",\n",
    "    func=lambda: print(\"Monitoring API health...\"),\n",
    "    every='5m',\n",
    "    tags=[\"monitoring\", \"api\", \"health-check\"],\n",
    "    metadata={\n",
    "        \"owner\": \"Engineering Team\",\n",
    "        \"endpoints\": [\"api.example.com\", \"api2.example.com\"],\n",
    "        \"alert_threshold_ms\": 500\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tasks with metadata and tags added!\\n\")\n",
    "\n",
    "# Display task information\n",
    "for task in scheduler.tasks:\n",
    "    print(f\"üìã Task: {task.name}\")\n",
    "    print(f\"   Tags: {', '.join(task.tags)}\")\n",
    "    print(f\"   Owner: {task.metadata.get('owner', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175824c",
   "metadata": {},
   "source": [
    "## 6. Max Instances Control\n",
    "\n",
    "Prevent multiple instances of the same task from running simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AutoCron()\n",
    "\n",
    "def heavy_processing():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting heavy processing...\")\n",
    "    time.sleep(10)  # Takes 10 seconds\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Processing complete!\")\n",
    "\n",
    "# Scheduled every 5 seconds but takes 10 seconds to complete\n",
    "scheduler.add_task(\n",
    "    name=\"heavy_task\",\n",
    "    func=heavy_processing,\n",
    "    every='5s',\n",
    "    max_instances=1  # Only allow 1 instance to run at a time\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Task configured with max_instances=1\")\n",
    "print(\"üìù If task is still running when next schedule time arrives, it will skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a66e20",
   "metadata": {},
   "source": [
    "## 7. Task Enable/Disable\n",
    "\n",
    "Temporarily disable tasks without removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AutoCron()\n",
    "\n",
    "# Add enabled task\n",
    "scheduler.add_task(\n",
    "    name=\"active_task\",\n",
    "    func=lambda: print(\"Running...\"),\n",
    "    every='10s',\n",
    "    enabled=True  # Task is active\n",
    ")\n",
    "\n",
    "# Add disabled task\n",
    "scheduler.add_task(\n",
    "    name=\"disabled_task\",\n",
    "    func=lambda: print(\"This won't run\"),\n",
    "    every='10s',\n",
    "    enabled=False  # Task is disabled\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tasks added!\\n\")\n",
    "\n",
    "for task in scheduler.tasks:\n",
    "    status = \"üü¢ ENABLED\" if task.enabled else \"üî¥ DISABLED\"\n",
    "    print(f\"{status}: {task.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79096b7b",
   "metadata": {},
   "source": [
    "## 8. Real-World Example: Complete ETL Pipeline\n",
    "\n",
    "Combining multiple advanced features in a realistic scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AutoCron()\n",
    "\n",
    "# Extract: Fetch data from API\n",
    "def extract_data():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] üì• Extracting data from API...\")\n",
    "    time.sleep(2)\n",
    "    if random.random() < 0.2:  # 20% failure rate\n",
    "        raise Exception(\"API connection failed\")\n",
    "    return \"raw_data\"\n",
    "\n",
    "# Transform: Process the data\n",
    "def transform_data():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] ‚öôÔ∏è  Transforming data...\")\n",
    "    time.sleep(3)\n",
    "    return \"processed_data\"\n",
    "\n",
    "# Load: Save to database\n",
    "def load_data():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] üíæ Loading data to database...\")\n",
    "    time.sleep(2)\n",
    "    return \"success\"\n",
    "\n",
    "# Configure ETL pipeline\n",
    "scheduler.add_task(\n",
    "    name=\"extract\",\n",
    "    func=extract_data,\n",
    "    every='1h',\n",
    "    priority=10,              # High priority\n",
    "    retries=3,                # Retry up to 3 times\n",
    "    retry_delay=10,           # Wait 10 seconds between retries\n",
    "    timeout=30,               # 30 second timeout\n",
    "    tags=[\"etl\", \"extract\", \"api\"],\n",
    "    metadata={\n",
    "        \"owner\": \"Data Team\",\n",
    "        \"api_endpoint\": \"https://api.example.com/data\"\n",
    "    }\n",
    ")\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"transform\",\n",
    "    func=transform_data,\n",
    "    every='1h',\n",
    "    priority=8,\n",
    "    timeout=60,\n",
    "    dependencies=[\"extract\"],  # Wait for extract to finish\n",
    "    tags=[\"etl\", \"transform\"],\n",
    "    metadata={\n",
    "        \"owner\": \"Data Team\",\n",
    "        \"transformation_rules\": \"v2.1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "scheduler.add_task(\n",
    "    name=\"load\",\n",
    "    func=load_data,\n",
    "    every='1h',\n",
    "    priority=7,\n",
    "    timeout=30,\n",
    "    dependencies=[\"transform\"],  # Wait for transform to finish\n",
    "    max_instances=1,            # Only one load at a time\n",
    "    tags=[\"etl\", \"load\", \"database\"],\n",
    "    metadata={\n",
    "        \"owner\": \"Data Team\",\n",
    "        \"target_database\": \"analytics_db\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Complete ETL Pipeline Configured!\\n\")\n",
    "print(\"üìä Pipeline: Extract (retry 3x) ‚Üí Transform (60s timeout) ‚Üí Load (1 instance)\")\n",
    "print(\"üè∑Ô∏è  All tasks tagged: 'etl' for easy filtering\")\n",
    "print(\"üë• Owner: Data Team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ae5f7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this demo, you learned:\n",
    "\n",
    "‚úÖ **Retries** - Automatic retry with configurable delays\n",
    "\n",
    "‚úÖ **Timeouts** - Prevent tasks from running too long\n",
    "\n",
    "‚úÖ **Priorities** - Control execution order (1-10 scale)\n",
    "\n",
    "‚úÖ **Dependencies** - Create task pipelines\n",
    "\n",
    "‚úÖ **Metadata & Tags** - Organize and categorize tasks\n",
    "\n",
    "‚úÖ **Max Instances** - Prevent concurrent executions\n",
    "\n",
    "‚úÖ **Enable/Disable** - Toggle tasks on/off\n",
    "\n",
    "### Next Steps:\n",
    "- Check out `03_async_tasks.ipynb` for async/await support\n",
    "- See `04_persistence.ipynb` for saving and loading tasks\n",
    "- Explore `05_safe_mode.ipynb` for secure task execution"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

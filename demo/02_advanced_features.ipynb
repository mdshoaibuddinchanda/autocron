{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9e70c47",
      "metadata": {},
      "source": [
        "# AutoCron Demo 2: Advanced Features\n",
        "\n",
        "This notebook demonstrates advanced scheduling features.\n",
        "\n",
        "## Features Covered:\n",
        "- Retries and error handling\n",
        "- Timeouts\n",
        "- Task priorities\n",
        "- Task dependencies\n",
        "- Task metadata and tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b69751",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "015bb841",
      "metadata": {},
      "outputs": [],
      "source": [
        "from autocron import AutoCron, schedule\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b140fbee",
      "metadata": {},
      "source": [
        "## 1. Retries and Error Handling\n",
        "\n",
        "Tasks can automatically retry on failure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fe975b4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:15 - INFO - Task 'unreliable_api_call' scheduled with: interval=10s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task with retries scheduled\n",
            "Will retry up to 3 times with 5-second delay\n"
          ]
        }
      ],
      "source": [
        "attempt_count = 0\n",
        "\n",
        "@schedule(every='10s', retries=3, retry_delay=5)\n",
        "def unreliable_api_call():\n",
        "    \"\"\"Simulates an unreliable API that might fail.\"\"\"\n",
        "    global attempt_count\n",
        "    attempt_count += 1\n",
        "\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Attempt #{attempt_count}\")\n",
        "\n",
        "    if random.random() < 0.6:\n",
        "        print(\"API call failed\")\n",
        "        raise Exception(\"Connection timeout\")\n",
        "\n",
        "    print(\"API call succeeded\")\n",
        "    return \"Data retrieved\"\n",
        "\n",
        "print(\"Task with retries scheduled\")\n",
        "print(\"Will retry up to 3 times with 5-second delay\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ec28c463",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:19 - INFO - Task 'flaky_task' scheduled with: interval=15s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task added with 5 retries and 3-second delay\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "def flaky_task():\n",
        "    if random.random() < 0.5:\n",
        "        raise Exception(\"Random failure\")\n",
        "    return \"Success\"\n",
        "\n",
        "scheduler.add_task(\n",
        "    name=\"flaky_task\",\n",
        "    func=flaky_task,\n",
        "    every='15s',\n",
        "    retries=5,\n",
        "    retry_delay=3\n",
        ")\n",
        "\n",
        "print(\"Task added with 5 retries and 3-second delay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d68b3444",
      "metadata": {},
      "source": [
        "## 2. Timeouts\n",
        "\n",
        "Prevent tasks from running too long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bbe11ae5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:22 - INFO - Task 'long_running_task' scheduled with: interval=20s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task with 10-second timeout scheduled\n",
            "If task takes longer than 10 seconds, it will be terminated\n"
          ]
        }
      ],
      "source": [
        "@schedule(every='20s', timeout=10)\n",
        "def long_running_task():\n",
        "    \"\"\"Task that might take too long.\"\"\"\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting long task\")\n",
        "\n",
        "    duration = random.randint(5, 15)\n",
        "    print(f\"Processing for {duration} seconds\")\n",
        "    time.sleep(duration)\n",
        "\n",
        "    print(\"Task completed\")\n",
        "    return \"Done\"\n",
        "\n",
        "print(\"Task with 10-second timeout scheduled\")\n",
        "print(\"If task takes longer than 10 seconds, it will be terminated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c4d6bcd3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:25 - INFO - Task 'slow_processor' scheduled with: interval=30s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task with timeout and retries configured\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "def slow_processing():\n",
        "    time.sleep(random.randint(3, 8))\n",
        "    return \"Processed\"\n",
        "\n",
        "scheduler.add_task(\n",
        "    name=\"slow_processor\",\n",
        "    func=slow_processing,\n",
        "    every='30s',\n",
        "    timeout=5,\n",
        "    retries=2,\n",
        "    retry_delay=2\n",
        ")\n",
        "\n",
        "print(\"Task with timeout and retries configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a0587c",
      "metadata": {},
      "source": [
        "## 3. Task Priorities\n",
        "\n",
        "Control execution order when multiple tasks are ready."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9c425463",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:28 - INFO - Task 'critical' scheduled with: interval=10s\n",
            "2026-02-22 15:38:28 - INFO - Task 'high' scheduled with: interval=10s\n",
            "2026-02-22 15:38:28 - INFO - Task 'normal' scheduled with: interval=10s\n",
            "2026-02-22 15:38:28 - INFO - Task 'low' scheduled with: interval=10s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tasks scheduled\n",
            "Priority map: {'critical': 10, 'high': 7, 'normal': 5, 'low': 2}\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "def critical_task():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] CRITICAL: Security check\")\n",
        "\n",
        "def high_priority_task():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] HIGH: Data backup\")\n",
        "\n",
        "def normal_task():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] NORMAL: Log rotation\")\n",
        "\n",
        "def low_priority_task():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] LOW: Cache cleanup\")\n",
        "\n",
        "priority_map = {\n",
        "    \"critical\": 10,\n",
        "    \"high\": 7,\n",
        "    \"normal\": 5,\n",
        "    \"low\": 2,\n",
        "}\n",
        "\n",
        "scheduler.add_task(name=\"critical\", func=critical_task, every='10s')\n",
        "scheduler.add_task(name=\"high\", func=high_priority_task, every='10s')\n",
        "scheduler.add_task(name=\"normal\", func=normal_task, every='10s')\n",
        "scheduler.add_task(name=\"low\", func=low_priority_task, every='10s')\n",
        "\n",
        "print(\"Tasks scheduled\")\n",
        "print(\"Priority map:\", priority_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335d9d09",
      "metadata": {},
      "source": [
        "## 4. Task Dependencies\n",
        "\n",
        "Run tasks only after other tasks complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2eb7cd6e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:32 - INFO - Task 'fetch' scheduled with: interval=1h\n",
            "2026-02-22 15:38:32 - INFO - Task 'process' scheduled with: interval=1h\n",
            "2026-02-22 15:38:32 - INFO - Task 'report' scheduled with: interval=1h\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task pipeline scheduled\n",
            "Pipeline order is managed in task logic: fetch -> process -> report\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "def fetch_data():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Step 1: Fetching raw data\")\n",
        "    time.sleep(2)\n",
        "    return \"raw_data.csv\"\n",
        "\n",
        "def process_data():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Step 2: Processing data\")\n",
        "    time.sleep(2)\n",
        "    return \"processed_data.csv\"\n",
        "\n",
        "def generate_report():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Step 3: Generating report\")\n",
        "    time.sleep(1)\n",
        "    return \"report.pdf\"\n",
        "\n",
        "scheduler.add_task(name=\"fetch\", func=fetch_data, every='1h')\n",
        "scheduler.add_task(name=\"process\", func=process_data, every='1h')\n",
        "scheduler.add_task(name=\"report\", func=generate_report, every='1h')\n",
        "\n",
        "print(\"Task pipeline scheduled\")\n",
        "print(\"Pipeline order is managed in task logic: fetch -> process -> report\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ac5d15",
      "metadata": {},
      "source": [
        "## 5. Task Metadata and Tags\n",
        "\n",
        "Organize and categorize tasks with metadata and tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "87233e9f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:35 - INFO - Task 'db_backup' scheduled with: interval=6h\n",
            "2026-02-22 15:38:35 - INFO - Task 'log_cleanup' scheduled with: interval=1d\n",
            "2026-02-22 15:38:35 - INFO - Task 'api_monitor' scheduled with: interval=5m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tasks with external metadata catalog added\n",
            "\n",
            "Task: db_backup\n",
            "Tags: backup, database, critical\n",
            "Owner: DevOps Team\n",
            "\n",
            "Task: log_cleanup\n",
            "Tags: maintenance, cleanup\n",
            "Owner: Platform Team\n",
            "\n",
            "Task: api_monitor\n",
            "Tags: monitoring, api, health-check\n",
            "Owner: Engineering Team\n",
            "\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "task_catalog = {\n",
        "    \"db_backup\": {\n",
        "        \"tags\": [\"backup\", \"database\", \"critical\"],\n",
        "        \"metadata\": {\n",
        "            \"owner\": \"DevOps Team\",\n",
        "            \"database\": \"production\",\n",
        "            \"retention_days\": 30,\n",
        "            \"notification_email\": \"ops@company.com\",\n",
        "        },\n",
        "    },\n",
        "    \"log_cleanup\": {\n",
        "        \"tags\": [\"maintenance\", \"cleanup\"],\n",
        "        \"metadata\": {\n",
        "            \"owner\": \"Platform Team\",\n",
        "            \"cleanup_age_days\": 7,\n",
        "            \"disk_threshold_gb\": 100,\n",
        "        },\n",
        "    },\n",
        "    \"api_monitor\": {\n",
        "        \"tags\": [\"monitoring\", \"api\", \"health-check\"],\n",
        "        \"metadata\": {\n",
        "            \"owner\": \"Engineering Team\",\n",
        "            \"endpoints\": [\"api.example.com\", \"api2.example.com\"],\n",
        "            \"alert_threshold_ms\": 500,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "scheduler.add_task(name=\"db_backup\", func=lambda: print(\"Backing up database\"), every='6h')\n",
        "scheduler.add_task(name=\"log_cleanup\", func=lambda: print(\"Cleaning old logs\"), every='1d')\n",
        "scheduler.add_task(name=\"api_monitor\", func=lambda: print(\"Monitoring API health\"), every='5m')\n",
        "\n",
        "print(\"Tasks with external metadata catalog added\\n\")\n",
        "for task in scheduler.list_tasks():\n",
        "    info = task_catalog.get(task.name, {})\n",
        "    print(f\"Task: {task.name}\")\n",
        "    print(f\"Tags: {', '.join(info.get('tags', []))}\")\n",
        "    print(f\"Owner: {info.get('metadata', {}).get('owner', 'N/A')}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f175824c",
      "metadata": {},
      "source": [
        "## 6. Max Instances Control\n",
        "\n",
        "Prevent multiple instances of the same task from running simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ddda055d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:40 - INFO - Task 'heavy_task' scheduled with: interval=5s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task configured\n",
            "This AutoCron version does not expose max_instances; long-running overlap control must be implemented in task logic\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "def heavy_processing():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting heavy processing\")\n",
        "    time.sleep(10)\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Processing complete\")\n",
        "\n",
        "scheduler.add_task(\n",
        "    name=\"heavy_task\",\n",
        "    func=heavy_processing,\n",
        "    every='5s',\n",
        ")\n",
        "\n",
        "print(\"Task configured\")\n",
        "print(\"This AutoCron version does not expose max_instances; long-running overlap control must be implemented in task logic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a66e20",
      "metadata": {},
      "source": [
        "## 7. Task Enable/Disable\n",
        "\n",
        "Temporarily disable tasks without removing them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "507b318c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:43 - INFO - Task 'active_task' scheduled with: interval=10s\n",
            "2026-02-22 15:38:43 - INFO - Task 'disabled_task' scheduled with: interval=10s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tasks added\n",
            "\n",
            "ENABLED: active_task\n",
            "DISABLED: disabled_task\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "active_task_id = scheduler.add_task(\n",
        "    name=\"active_task\",\n",
        "    func=lambda: print(\"Running\"),\n",
        "    every='10s',\n",
        ")\n",
        "\n",
        "disabled_task_id = scheduler.add_task(\n",
        "    name=\"disabled_task\",\n",
        "    func=lambda: print(\"This will not run while disabled\"),\n",
        "    every='10s',\n",
        ")\n",
        "\n",
        "disabled_task = scheduler.get_task(task_id=disabled_task_id)\n",
        "if disabled_task is not None:\n",
        "    disabled_task.enabled = False\n",
        "\n",
        "print(\"Tasks added\\n\")\n",
        "for task in scheduler.list_tasks():\n",
        "    status = \"ENABLED\" if task.enabled else \"DISABLED\"\n",
        "    print(f\"{status}: {task.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79096b7b",
      "metadata": {},
      "source": [
        "## 8. Real-World Example: Complete ETL Pipeline\n",
        "\n",
        "Combining multiple advanced features in a realistic scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fb3a7ff8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-22 15:38:46 - INFO - Task 'extract' scheduled with: interval=1h\n",
            "2026-02-22 15:38:46 - INFO - Task 'transform' scheduled with: interval=1h\n",
            "2026-02-22 15:38:46 - INFO - Task 'load' scheduled with: interval=1h\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete ETL pipeline configured\n",
            "\n",
            "Pipeline sequence: extract -> transform -> load\n",
            "External task catalog: {'extract': {'owner': 'Data Team', 'pipeline_step': 1}, 'transform': {'owner': 'Data Team', 'pipeline_step': 2}, 'load': {'owner': 'Data Team', 'pipeline_step': 3}}\n"
          ]
        }
      ],
      "source": [
        "scheduler = AutoCron()\n",
        "\n",
        "def extract_data():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Extracting data from API\")\n",
        "    time.sleep(2)\n",
        "    if random.random() < 0.2:\n",
        "        raise Exception(\"API connection failed\")\n",
        "    return \"raw_data\"\n",
        "\n",
        "def transform_data():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Transforming data\")\n",
        "    time.sleep(3)\n",
        "    return \"processed_data\"\n",
        "\n",
        "def load_data():\n",
        "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] Loading data to database\")\n",
        "    time.sleep(2)\n",
        "    return \"success\"\n",
        "\n",
        "task_catalog = {\n",
        "    \"extract\": {\"owner\": \"Data Team\", \"pipeline_step\": 1},\n",
        "    \"transform\": {\"owner\": \"Data Team\", \"pipeline_step\": 2},\n",
        "    \"load\": {\"owner\": \"Data Team\", \"pipeline_step\": 3},\n",
        "}\n",
        "\n",
        "scheduler.add_task(\n",
        "    name=\"extract\",\n",
        "    func=extract_data,\n",
        "    every='1h',\n",
        "    retries=3,\n",
        "    retry_delay=10,\n",
        "    timeout=30,\n",
        ")\n",
        "\n",
        "scheduler.add_task(\n",
        "    name=\"transform\",\n",
        "    func=transform_data,\n",
        "    every='1h',\n",
        "    timeout=60,\n",
        ")\n",
        "\n",
        "scheduler.add_task(\n",
        "    name=\"load\",\n",
        "    func=load_data,\n",
        "    every='1h',\n",
        "    timeout=30,\n",
        ")\n",
        "\n",
        "print(\"Complete ETL pipeline configured\\n\")\n",
        "print(\"Pipeline sequence: extract -> transform -> load\")\n",
        "print(\"External task catalog:\", task_catalog)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea7ae5f7",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this demo, you learned:\n",
        "\n",
        " **Retries** - Automatic retry with configurable delays\n",
        "\n",
        " **Timeouts** - Prevent tasks from running too long\n",
        "\n",
        " **Priorities** - Control execution order (1-10 scale)\n",
        "\n",
        " **Dependencies** - Create task pipelines\n",
        "\n",
        " **Metadata & Tags** - Organize and categorize tasks\n",
        "\n",
        " **Max Instances** - Prevent concurrent executions\n",
        "\n",
        " **Enable/Disable** - Toggle tasks on/off\n",
        "\n",
        "### Next Steps:\n",
        "- Check out `03_async_tasks.ipynb` for async/await support\n",
        "- See `04_persistence.ipynb` for saving and loading tasks\n",
        "- Explore `05_safe_mode.ipynb` for secure task execution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
